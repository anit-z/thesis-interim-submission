import os
import subprocess
import pandas as pd
from multiprocessing import Pool
from tqdm import tqdm

# Configuration
AUDIO_DIR = "/scratch/s6055702/ser_credit_rating/earnings21/downgraded_audio"
OUTPUT_DIR = "/scratch/s6055702/ser_credit_rating/earnings21/downgraded_audio"
OPENSMILE_BIN = "/scratch/s6055702/ser_credit_rating/opensmile/build/progsrc/smilextract/SMILExtract"
OPENSMILE_CONFIG = "/scratch/s6055702/ser_credit_rating/opensmile/config/compare16/ComParE_2016.conf"
NUM_PROCESSES = 8
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Features we want to extract (from the attribute list)
TARGET_FEATURES = [
    'audspec_lengthL1norm_sma_range',  # Energy-related
    'pcm_RMSenergy_sma_range',         # Energy contour
    'F0semitoneFrom27.5Hz_sma_range',  # Pitch variability
    'voicingFinalUnclipped_sma_range',  # Pause detection
    'speechFrames',                    # Speech rate related
    'speechFramesVoiced'               # Speech rate related
]

def extract_features(audio_path):
    """Run openSMILE to extract features."""
    base_name = os.path.basename(audio_path).replace(".wav", "")
    output_csv = os.path.join(OUTPUT_DIR, f"{base_name}_features.arff")
    
    cmd = [
        OPENSMILE_BIN,
        "-C", OPENSMILE_CONFIG,
        "-I", audio_path,
        "-O", output_csv,
        "-noconsoleoutput", "1",
        "-loglevel", "0"
    ]
    
    try:
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            universal_newlines=True
        )
        stdout, stderr = process.communicate()
        
        if process.returncode != 0:
            error_msg = stderr.strip() if stderr else f"Command failed with exit code {process.returncode}"
            return (audio_path, None, error_msg)
            
        return (audio_path, output_csv, True)
    except Exception as e:
        return (audio_path, None, f"Unexpected error: {str(e)}")

def parse_arff_file(arff_path):
    """Parse ARFF format files generated by OpenSMILE."""
    try:
        with open(arff_path, 'r') as f:
            content = f.readlines()
        
        # Extract attribute names and their order
        attributes = []
        data_start = -1
        for i, line in enumerate(content):
            line = line.strip()
            if line.startswith('@attribute'):
                attr_name = line.split()[1]
                attributes.append(attr_name)
            elif line == '@data':
                data_start = i + 1
                break
        
        if data_start == -1 or not attributes:
            raise ValueError("Invalid ARFF format - missing @data section or attributes")
        
        # Find the data line (last non-empty line after @data)
        data_line = None
        for line in content[data_start:]:
            if line.strip():
                data_line = line.strip()
        
        if not data_line:
            raise ValueError("No data found in ARFF file")
        
        # Split data values
        values = data_line.split(',')
        if len(values) != len(attributes):
            raise ValueError(f"Attribute count ({len(attributes)}) doesn't match data values ({len(values)})")
        
        # Create feature dictionary with only our target features
        features = {}
        for attr, val in zip(attributes, values):
            if attr in TARGET_FEATURES:
                try:
                    features[attr] = float(val)
                except ValueError:
                    features[attr] = val
        
        return pd.DataFrame([features])
    
    except Exception as e:
        print(f"Error parsing {arff_path}: {str(e)}")
        return None

def main():
    # Verify OpenSMILE binary exists
    if not os.path.exists(OPENSMILE_BIN):
        print(f"Error: OpenSMILE binary not found at {OPENSMILE_BIN}")
        return
    
    # Verify config file exists
    if not os.path.exists(OPENSMILE_CONFIG):
        print(f"Error: Config file not found at {OPENSMILE_CONFIG}")
        return
    
    # Get audio files
    audio_files = sorted([os.path.join(AUDIO_DIR, f) for f in os.listdir(AUDIO_DIR) if f.endswith(".wav")])
    print(f"Found {len(audio_files)} audio files.")
    
    # Process files in parallel
    with Pool(processes=NUM_PROCESSES) as pool:
        results = []
        for result in tqdm(pool.imap(extract_features, audio_files), total=len(audio_files)):
            results.append(result)
    
    # Process results
    successful = [r[1] for r in results if r[2] is True]
    failed = [(r[0], r[2]) for r in results if r[2] is not True]
    
    print(f"\nSuccess: {len(successful)} | Failed: {len(failed)}")
    if failed:
        print("\nFailure details:")
        for f in failed[:5]:
            print(f"{os.path.basename(f[0])}: {f[1]}")
    
    # Combine results
    if successful:
        dfs = []
        for arff_file in tqdm(successful, desc="Processing ARFF files"):
            try:
                df = parse_arff_file(arff_file)
                if df is not None:
                    df.insert(0, "audio_file", os.path.basename(arff_file.replace("_features.arff", ".wav")))
                    dfs.append(df)
            except Exception as e:
                print(f"Error processing {arff_file}: {str(e)}")
        
        if dfs:
            # Combine all dataframes
            combined_df = pd.concat(dfs, ignore_index=True)
            
            # Select only the features that were actually found
            available_features = [f for f in TARGET_FEATURES if f in combined_df.columns]
            combined_df = combined_df[['audio_file'] + available_features]
            
            # Save final output
            output_path = os.path.join(OUTPUT_DIR, "all_features_combined.csv")
            combined_df.to_csv(output_path, index=False)
            print(f"\nCombined features saved to: {output_path}")
            print(f"Extracted features: {', '.join(available_features)}")
            
            # Report missing features
            missing = [f for f in TARGET_FEATURES if f not in combined_df.columns]
            if missing:
                print("Warning: Missing features:", missing)
        else:
            print("No valid data was extracted from any files.")

if __name__ == "__main__":
    main()